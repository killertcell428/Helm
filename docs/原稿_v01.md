# 事前ハッカソン用 プレゼン原稿

## 冒頭：自己紹介と課題の共感（〜45秒）

「僕はこれまで、**AIグランドデザインや業務変革に向けた設計・開発・分析**を専門とするビジネスコンサルタントとして、大手企業のAI活用プロジェクトを数多く支援してきました。

その現場で一番痛感してきたのは、**「いい施策を出してから、実際に動くまでがとにかく遅い」**という構造的な課題です。

ステークホルダーは多く、会議は何度も開かれ、複数の上司の意見や、言葉には出てこない暗黙の力学が絡み合う。
どの企業でも共通していて、本来前に進めたいはずの人たち自身が、その構造に絡め取られてしまう。
これまでは、第三者である僕らが必死に顧客理解を深めて、**「もうやりましょう」とお尻を叩いて**進めてきました。

**その経験から、「この構造そのものをAIで見える化して、前に進む力に変えられないか」**――
そこから生まれたのが、今日お見せする **Helm** というプロジェクトです。」

---

## 1. 問題提起：既存組織の意思決定は「構造的に壊れている」（〜50秒）

「組織の意思決定プロセスには、以下の**構造・組織的な問題**が存在します。

**課題：AI主導の意思決定を阻む「3つの壁」**

**第一の壁：責任境界の曖昧性**

大企業では、研究で『この仮説は棄却すべきか』、ビジネスで『この事業は撤退すべきか』という重要な判断の**責任者が不明確**になります。

**第二の壁：バイアスによる修正困難化**

**忖度・楽観・既得権益による歪み**が組織的なバイアスとなり、実験データや市場反応が乏しくなっても、構造的な軌道修正が起きません。

**第三の壁：人主導によるAI活用の限界**

実験ログ・会議ログ・KPI変更履歴など、膨大なシグナルを人が手作業で監視する必要があります。AIは「呼び出されるだけ」の存在であり、組織の構造的問題を自ら検知することができません。

**調査事例（大企業）**

従業員1,000名以上の企業では、以下の実データが報告されています：

- **平均意思決定リードタイム：70〜85日**
- **新規事業の失敗率：約70%**
- **年間機会損失：約20億円**

Helmは、この構造的問題を自動で検知し、正しいタイミングで経営層を呼び出すことで、組織そのものを賢くするプラットフォームです。」

---

## 2. どう解決するか：Helmの機能コンセプト（〜40秒）

「**Helmは、組織そのものを評価・判断するシステム**を構築します。

従来の
- ❌「人がAIを呼び出す」
- ⬇
- ⭕「AIが人を呼び出す」

へ転換します。

**Helmを構成する3つの中核機能：**

**① 多角的な評価・判断システム**
- **ルールベース（0.6） × LLM（0.4）** のハイブリッド評価
- 4視点で同時評価（経営者、経営企画、現場、ガバナンス）
- 見落としのない**統合判断**を実現

**② AIが人を呼び出し、判断を依頼**
- 構造的問題を検知すると、AIが自動で**役員 / 部長 / スタッフ**を特定
- 人がAIを監視するのではなく、**AIが組織を監視し、人に判断を求める**

**③ 学習・改善PDCAの自動化**
- 観測→評価→介入→実行→再観測のループを自動化
- 組織構造の「壊れ方」を学習し、時間とともに**組織自体が賢くなる**」

---

## 3. 実行プロセスとHybrid評価アーキテクチャ（〜1分10秒）

「**実行プロセス（5ステップ）**

1. **データ取り込み**：Google Meet / Chat / 会議資料から議事録・ログを取得し構造化
2. **検知・評価**：ルールベース＋マルチLLMで問題特定
3. **アラート発行**：責任モデルに基づきAIが人を呼び出す
4. **承認・指示**：人が確認・修正し、AIに実行権限付与
5. **AI自律実行**：タスク分解、資料作成、会議設定まで実行

**Hybrid評価アーキテクチャ：なぜルール×LLMなのか**

**ルールベースの限界**：数値は正常だが「空気が異常」を見逃す

**LLM単体の限界**：楽観バイアス・ハルシネーション

**INPUT（ルールベース）**
- KPI下方修正回数 > 2
- 撤退議論キーワード：なし
- 判断集中率（最も多く発言した人の発言数 / 総発言数） > 40%

→ **見逃しゼロの安全網**

**CONTEXT ANALYSIS（LLM）**
- 経営者視点（0.4）：全社リスク
- 経営企画視点（0.3）：ポートフォリオ整合
- 現場視点（0.2）：現場負荷
- ガバナンス視点（0.1）：コンプラ・報告遅延

→ **文脈理解で過剰反応を抑制**

**FINAL DECISION**

```
0.6 × Rule + 0.4 × LLM
Weighted Ensemble Score
```

- 重要度・緊急度は**最も安全側の評価を強制採用**

**アーキテクチャの技術的な特徴：**

| カテゴリ | 技術 | 選定理由 | 具体的活用方法 |
|---------|------|---------|---------------|
| **フロントエンド** | Next.js 16 | Reactベースのフレームワークで、SSRとSSGをサポート。デモページの高速表示を実現 | Case1/Case2/Case3のデモページを構築。API Clientでバックエンドと通信 |
| | TypeScript | 型安全性の確保により、開発時のエラーを早期発見 | APIレスポンスの型定義、コンポーネントの型安全性を確保 |
| | WebSocket | リアルタイム進捗更新に使用 | AI自律実行中の進捗をリアルタイムで配信 |
| **バックエンド** | FastAPI | PythonベースのAPIフレームワークで、非同期処理とWebSocketをサポート | REST APIエンドポイントとWebSocketエンドポイントを実装 |
| | Python 3.11+ | 主要なプログラミング言語。型ヒントとパフォーマンス改善を活用 | サービス層の実装、LLM統合、データ処理 |
| **AI/ML** | Gemini 2.0 Flash (Gen AI SDK) | Google Cloudの生成AIモデル。マルチ視点評価と構造的問題検知に最適 | マルチ視点LLM分析（4つのロール視点から評価）、構造的問題検知、タスク生成、説明文生成 |
| **Google Cloud統合** | Google Meet API | 議事録取得に使用 | 会議議事録の取得、発言者抽出、KPI検出 |
| | Google Chat API | チャットメッセージ取得に使用 | チャットログの取得、本音の兆候検出 |
| | Google Workspace API | 資料生成と通知送信に使用 | 資料ドラフト作成、関係者への通知送信 |
| | Google Drive API | ファイル保存と共有に使用 | 生成された資料の保存、ダウンロードURL生成 |

バックエンドは **ADK（Agent Development Kit、Googleが提供するAIエージェント開発ツールキット）ベースのマルチエージェント構成**を採用しています。

**マルチエージェントシステム**とは、複数のAIエージェント（専門的な役割を持つAIプログラム）が協調して動作するシステムです。具体的には、以下の3つのAIエージェントが協調して動作します：

1. **Research Agent（リサーチエージェント）**：市場データや社内データのリサーチを担当
2. **Analysis Agent（分析エージェント）**：構造的問題の検知とスコアリングを担当
3. **Notification Agent（通知エージェント）**：関係者への通知ドラフト作成を担当

すべての処理は、APIとサービス層のインターフェースで抽象化されているため、モックから実データへの切り替えが容易です。

**LLMの使い方の工夫**として、

- **ルールベース評価**：KPI下方修正回数、判断集中率（最も多く発言した人の発言数 / 総発言数）など、定量的な指標を自動計算
- **マルチ視点LLM評価**：経営者、経営企画、現場スタッフ、ガバナンスなど、複数のロール視点から Gemini で評価
- **アンサンブルスコアリング（統合評価）**：これらを組み合わせることで、より保守的で信頼性の高い評価を実現

この技術的な設計により、構造的なリスクを過小評価せず、かつ過剰なアラートも避けるバランスを取っています。

それでは、実際のデモで、Helmがどのように動作するかをお見せします。」

---

## 4. Case1 デモ：戦略見直しの構造的先送り（〜3分30秒）

### 4-1. Before（人だけの場合）（〜40秒）

「では Case1 をお見せします。テーマは **『戦略見直しの構造的先送り』** です。

ここが Helm 導入前の状態です。（画面の Before セクションを指す）

NeoWave Communicationsという通信系IT大手の四半期経営会議の議事録と、その後の経営企画チャットを見てみましょう。

- CFOが『モバイルARPUは前年同期比▲6.2%、5G設備投資は当初計画比＋18%』と報告しているのに、
- CEOは『厳しいが、我々の戦略自体は間違っていないと思う』と正当化し、
- 会議の結論は『2025年度計画は維持。次回進捗報告は3か月後』となっている。

一方、会議後のチャットでは、

- 『数字かなり厳しかったですね』
- 『撤退案を口に出せる空気ではなかったですね』
  と、本音が漏れているのに、それが会議には反映されない。

下にある指標を見ると、意思決定リードタイムが 70〜85日、
代替案検討率も 10％未満、という "よくあるまずい状態" になっています。

この状態で、Helm を入れるとどう変わるのか、をお見せします。」

**（ここで「Helmがある場合を見る」ボタンをクリック）**

### 4-2. データ受領と構造診断（〜90秒）

「まず Helm がやるのは、会議とチャットのデータの取り込みです。
（画面の「データ受領直後」状態を指す）

ここで『Helmがデータを受領』と出ていて、
さっきの経営会議とチャットログが Helm のバックエンドに入ります。

**技術的な裏側では：**

- Google Meet API から議事録を取得し、発言者・KPI・リスクキーワードをパース
- Google Chat API からチャットログを取得し、本音の兆候を検出
- すべての処理は、モックと実データで同じインターフェースを使っているため、切り替えが容易です

**"今、HelmのAIがやっていること"** という欄を見ると、
『議事録とチャットから構造的問題の兆候を抽出中...』と説明しています。
このように、**ローディング中も裏で何をしているかが分かるようになっています。**

次に『Helm構造診断完了』の画面に進むと、（画面遷移）

総合スコアと、重要度・緊急度、それから検出された構造的問題が出ます。

**技術的な実装の工夫：**

- ここでは **「B1_正当化フェーズ」（KPI悪化が続いているにも関わらず、戦略変更の議論が行われない状態）** が検出されていて、
- **ルールベース評価**：KPI 下方修正の回数、反対意見の無視、判断集中率（最も多く発言した人の発言数 / 総発言数）など、定量的な指標を自動計算
- **マルチ視点LLM評価**：経営者、経営企画、現場スタッフ、ガバナンスなど、複数のロール視点から Gemini で評価
- これらを**アンサンブルスコアリング**することで、**70点台のスコア**がついています

さらに下を見ると、
経営者や経営企画、現場スタッフ、ガバナンスなど、**ロールごとの視点別スコア** が並んでいて、
それぞれのロールが異なる視点から評価していることが分かります。

**技術的なポイント：**
各ロールの評価は、Gemini に対して異なるプロンプト（経営者視点、経営企画視点など）を送ることで実現しています。各視点は、実際の組織における役割を模倣しており、それぞれ異なる立場から構造的リスクを評価します。
これにより、単一のLLM評価ではなく、多角的な視点からの評価が可能になっています。

右側の「スコアの見方」という説明カードで、
『ルールベースの構造指標と、複数ロールの視点別スコアをアンサンブルして総合スコアを出している』
ことも明示しています。

これにより、**構造的なリスクが強い場合は、視点別スコアよりも総合スコアが抑えめに出る**という、
より保守的な評価ができるようになっています。

この**ルールベース + マルチ視点LLMのアンサンブル**というアプローチは、Helmの技術的な差別化ポイントの1つです。」

### 4-3. エスカレーション提案と経営層判断（〜50秒）

「次に Helm は、**誰にどのレベルでエスカレーション（上位への報告）すべきか** を提案します。
（画面の「経営層の判断」状態を指す）

この画面では、
『この状態は経営層レイヤーまで上げるべきだ』という提案と、その理由がテキストで出ています。

Helmからの提案として、

- 次回の経営会議で『継続・縮小・撤退の 3案比較』を強制議題化すること、
- 撤退案の提案責任者を明示すること、
- KPI トリガー（ARPU▲X%で再検討）を数値で決めること、

といった「人が本来やるべき議論の枠組み」を、AI が先に用意してくれます。

右側で、経営層が『了承する』あるいは『一部修正して実行』を選ぶと、
その判断が記録されて、**次アクション確定** の画面に進みます。

ここで重要なのは、**AIが止まるのは、判断が必要な時だけ**ということです。
Helmは、判断の枠組みを用意しますが、最終的な意思決定は人間（経営層）が行います。」

### 4-4. AI自律実行と結果（〜90秒）

「そして実行フェーズに入ると、
『AI自律実行中』の画面で、何をやっているかが具体的に見えるようになっています。
（画面の「AI自律実行中」状態を指す）

**技術的な実装：**
進捗の更新は **WebSocket** でリアルタイムに配信されています。
バックエンドの各エージェントがタスクを完了するたびに、フロントエンドに進捗を送信し、
ユーザーは待ち時間中も何が起きているかを把握できます。

**"今、HelmのAIがやっていること"** という欄を見ると、
『市場・社内データのリサーチ、3案シミュレーション、資料ドラフト、通知ドラフトを生成中...』
と説明しています。

画面には、5つのタスクが進捗バーと一緒に表示されます：

**技術的な裏側では、ADKベースのマルチエージェント構成が動作しています：**

1. **市場・社外データのリサーチ**（進捗20%）

   - **Research Agent** が業界レポートや競合動向のサマリーを取得
   - 現在はモックデータですが、実データ接続時は外部APIや社内DWHと連携
2. **社内データ・過去案件の統合**（進捗40%）

   - **Analysis Agent** が社内の過去案件・KPIのメタデータを集約し、類似ケースとリスクパターンを抽出
   - 構造的問題パターンのマッチングを実行
3. **3案比較（継続・縮小・撤退）のシミュレーション**（進捗60%）

   - **Analysis Agent** が継続・縮小・撤退それぞれの売上・コスト・利益とリスクレベルを試算
   - Gemini を使って財務シミュレーションのドラフトを生成
4. **資料ドラフト作成と関係者への通知準備**（進捗80%）

   - **Notification Agent** が Google Docs形式の資料ドラフトを生成
   - CFOや各本部長向けの事前共有メッセージ（下書き）を組み立て
   - Google Drive API を使ってドキュメントを作成
5. **次回会議のアジェンダ案作成**（進捗100%）

   - **Notification Agent** が次回経営会議の正式議題候補として整理
   - Google Calendar API との連携を想定（現在はモック）

**マルチエージェント構成の利点：**
各エージェントが独立して動作するため、並列処理が可能で、全体の実行時間を短縮できます。
また、エージェントごとに責任が分離されているため、保守性と拡張性が高い設計になっています。

ここでも"今、HelmのAIがやっていること" のサマリで、
**『資料ドラフトや通知ドラフトまでは AI が自律実行し、
実際の招集・送信・最終決裁は人が行う前提』**であることを明示しています。

最終的な『実行結果受領』の画面では、（画面遷移）
3案比較資料や関係者への通知ドラフトへのリンクが出てきて、
さらにその詳細は成果物タブ（別タブ）で確認できるようになっています。

最後の『Next Cycle』では、Helm 導入前後で

- **意思決定リードタイムが 70〜85日 → 2日以内に**（97%削減、35倍改善）、
- **代替案検討率が 10％未満 → 50％以上に**（5倍以上改善）、
- **構造スコアが 75点 → 40点に**（47%改善）、
- **経営層レビュー負荷が 15h/週 → 3h/週に**（80%削減）、
- **Zombie Project検知率が 0% → 90%以上に**（Zombie Projectとは、失敗しているにも関わらず継続されているプロジェクトのこと）

といったフェルミ推定ベースのインパクトもまとめています。

**経済効果（フェルミ推定、信頼性：低）：**
- 意思決定速度改善による機会損失削減：年間**約19億円規模**（20億円→1億円以下）
- Zombie Project（失敗しているにも関わらず継続されているプロジェクト）削減による無駄な投資削減：年間**約88億円規模**（123億円→35億円）
- 経営層の時間確保による機会創出：年間**約10億円規模**
- **合計：年間約100-120億円規模の経済効果**

3週間後の経営会議では、撤退案スライドが議題の1つとして自然に含まれ、
CFOが「投資凍結オプション」の財務影響について具体的に言及するようになります。

**Helmは、次の経営会議データを受領し、再び構造分析を実施します。**
今回は「撤退案」が自然に議論され、意思決定スピードが向上します。
組織は学習し続け、時間とともにより賢くなっていく、という設計です。」

---

## 5. クロージング：Helmの価値と差別化（〜50秒）

「まとめると、Helm は
単にレポートを書くツールではなく、
**『なぜ決まらないのか』という構造的な問題を検知し、
正しいタイミングと正しいレベルで経営層を呼び出す "自律改善の航海士"** です。

> **「AIを賢くするのではない。  
> "人とAIでできた組織"を賢くする。」**

**既存AIエージェントとの差分：**

| 観点 | 既存AI | Helm |
|------|--------|------|
| 自律性 | 行動 | 判断 |
| 責任 | 人間任せ | 内部モデル化 |
| 組織 | 前提 | 最適化対象 |
| 人間 | 操作者 | 呼び出される存在 |
| 失敗分析 | 内容 | 構造 |

**将来展望：**
- Phase1：新規事業・R&D（現在）
- Phase2：危機管理・予算配分（6–12ヶ月）
- Phase3：組織変革・M&A（12–24ヶ月）
- Phase4：人事評価・昇進（24–36ヶ月）

**最終的なビジョン：AI会社パッケージ**

AIが以下を自動生成：
1. 組織構造設計
2. メンバー選定
3. ロードマップ生成
4. 実作業提案

→ **数時間で体制構築、数日でPJ始動**

正解のない航海を導く、組織単位の自律改善型AI — それが Helm です。

ご清聴ありがとうございました。」

---

## 補足：デモの流れと画面対応メモ

### デモ開始前の準備

- ブラウザで `/demo/case1` を開いておく
- デモは「Before」状態から開始

### デモの流れ（Case1）

1. **Before（人だけの場合）** → 「Helmがある場合を見る」ボタンをクリック
2. **データ受領直後** → 「今、HelmのAIがやっていること」カードを指す
3. **Helm構造診断完了** → 総合スコア、視点別スコア、「スコアの見方」カードを説明
4. **経営層の判断** → Helmからの提案と、経営層の選択肢を説明
5. **次アクション確定** → 確定されたアクションを確認
6. **AI自律実行中** → 5つのタスクの進捗と「今、HelmのAIがやっていること」カードを説明
7. **実行結果受領** → 成果物へのリンクを確認（必要に応じて別タブで成果物ページを開く）
8. **Next Cycle** → 導入前後の効果指標を比較

### 重要なポイント

- **「今、HelmのAIがやっていること」カード**は各状態で表示されるので、必ず指す
- **スコアの見方**カードで、ルールベースとマルチ視点のアンサンブル評価を説明
- **成果物ページ**は別タブで開けるので、必要に応じて参照
- デモ中は「AIが止まるのは、判断が必要な時だけ」を繰り返し強調

### 想定質問への回答準備

#### 技術・実装に関する質問

- **Q: モックと実装の違いは？**A: 現在はモックデータですが、APIとサービス層は本番前提のインターフェースで実装済み。Google Workspace APIとの連携部分は、モックサービスと実APIサービスで同じインターフェースを実装しているため、環境変数で切り替え可能です。2月の本戦までに実データPoCを予定。
- **Q: ADK（Agent Development Kit）の活用方法は？**A: ADKベースで3つのエージェント（Research、Analysis、Notification）を実装しています。各エージェントは独立して動作し、並列処理が可能です。エージェント間の通信は、メッセージキューを介して行い、責任の分離と拡張性を確保しています。
- **Q: マルチ視点LLM評価の実装は？**A: 各ロール（経営者、経営企画、現場スタッフ、ガバナンスなど）に対して、異なるプロンプトテンプレートを用意しています。Gemini APIに対して、ロールごとに異なる視点を指定したプロンプトを送信し、それぞれの評価結果を収集。その後、ルールベース評価とアンサンブルスコアリング（統合評価）することで、より信頼性の高いスコアを算出しています。
- **Q: WebSocketによるリアルタイム更新の実装は？**A: FastAPIのWebSocketエンドポイントを実装し、各エージェントがタスクを完了するたびに進捗をブロードキャストしています。WebSocket接続が失敗した場合は、ポーリング方式にフォールバックする設計になっています。
- **Q: スコアの精度は？**A: ルールベース評価とマルチ視点LLM評価をアンサンブルすることで、より保守的な評価を実現。構造的なリスクが強い場合は、視点別スコアよりも総合スコアが抑えめに出るように設計しています。実データでの検証とチューニングを継続予定。
- **Q: Google Workspace APIとの連携は？**A: Google Meet、Chat、Drive、Docsの各APIと連携。OAuth 2.0認証を使用し、スコープを最小限に抑えた設計です。現在はモックサービスで動作していますが、実API接続時も同じインターフェースを使用するため、コード変更は最小限で済みます。
- **Q: 競合との違いは？**
  A: 既存ツールはタスク最適化、Helmは組織構造そのものを観測・評価・再設計。観測対象、介入方法、学習の単位が根本的に異なります。技術的には、ルールベース + マルチ視点LLMのアンサンブルスコアリング、ADKベースのマルチエージェント構成、Google Workspace APIとの深い統合が差別化ポイントです。

#### 組織・運用に関する質問

- **Q: 監視の対象がメンバーだけでなくリーダーも含まれると、働く雰囲気に影響が出そうなのでは？**A: おっしゃる通り、監視という言葉は誤解を招く可能性があります。Helmは「監視」ではなく「構造的問題の検知とサポート」を目的としています。重要なのは、**Helmは個人を評価するのではなく、組織の判断構造そのものを観測する**ということです。例えば、リーダーが「マネジメント能力が届かない範囲」で判断に迷っている場合、Helmはそれを「構造的な問題」として検知し、経営層に適切なタイミングでエスカレーションすることで、リーダーをサポートします。個人の能力の問題ではなく、組織の判断構造の問題として扱うことで、働く雰囲気を損なわずに改善できると考えています。
- **Q: 監査に特化するといいのでは？例えば、賞金を振り込む際の流れでコンプラ違反などがないかのレビューなど。**A: 素晴らしいアイデアです。確かに、Helmの構造的問題検知の技術は監査領域にも応用できます。例えば、売上計画に対して進捗が遅れている場合、Helmは「なぜ遅れているのか」という構造的な原因（判断権限の不明確さ、エスカレーション基準の欠如など）を検知し、コンプライアンス違反のリスクを事前に防ぐことができます。現在のデモでは新規事業の意思決定に焦点を当てていますが、将来的には監査・コンプライアンス領域への展開も視野に入れています。
- **Q: 「ボトルネックはお前だ」と言われるのが怖い。責任を個人に押し付けられるのでは？**A: これは非常に重要な懸念です。Helmの設計思想として、**責任はすべて組織の役員に統合される**という前提があります。Helmは「誰が悪いか」を指摘するのではなく、「組織の判断構造に問題がある」ことを検知し、役員が適切な介入（ロール再編、権限の明確化、エスカレーション基準の設定など）を行うための情報を提供します。個人の責任追及ではなく、組織構造の改善を目的としているため、「ボトルネックはお前だ」という個人攻撃にはなりません。むしろ、Helmが検知するのは「判断が集中しすぎている」「エスカレーション基準が不明確」といった構造的な問題であり、それらを経営が組織レベルで解決することで、個人の負担を減らすことができます。
- **Q: 誰にどこまで言うの？マネジメント能力が届かない範囲があるのでは？**
  A: まさにその通りです。Helmは「マネジメント能力が届かない範囲」を構造的問題として検知し、サポートすることを目的としています。
  例えば、現場のマネージャーが「この判断を上司に上げるべきか、自分で決めていいのか」と迷っている場合、Helmはその判断の迷いを検知し、適切なエスカレーション基準を提案します。
  重要なのは、Helmが「誰にどこまで言うべきか」を自動的に判断するのではなく、経営層が組織の判断構造を設計する際の情報を提供することです。
  最終的な判断は人間が行い、Helmはその判断をサポートする役割に徹します。
