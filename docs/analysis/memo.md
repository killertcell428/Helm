
## ①審査員（業界テックリーダー）視点の離脱要因

対象例：アクセンチュア株式会社 / ゆめみ CTO / 株式会社松尾研究所 / Google Cloud Japan のAI Solutions Architect 等

### 審査員が“読むのをやめる”ポイント（＝突っ込まれるポイント）

**A. 新規性の主張が強いが、既存研究・既存領域との線引きが曖昧**

* 「組織構造を観測・評価・再設計」は面白い一方で、審査員は
  “それって意思決定インテリジェンス / プロセスマイニング / 行動分析 / ガバナンス系の延長では？”
  と連想します。
* CrewAI/AutoGen/PMツールとの差分は書けているけど、**近い隣接領域との差分**が薄い。

**改善案**

* 「何を新規にしたか」を1枚で言い切る：
  * 例：*“会議・チャットという非構造ログから、意思決定の失敗パターンを検知し、責任境界モデルに沿って承認フローまで接続した”*
* さらに「これはやらない（スコープ外）」も明確化する。(既存のAIエージェントやタスクツールの役割、単純な行動分析やガバナンスツールとは違う部分がスコープ。)

---

**B. 評価設計（検知精度・誤検知・再現性）が弱いと見なされる**

* 69点/70点、重み0.6/0.4 は提示されているが、
  「なぜその重み？」「閾値はどう決めた？」「誤検知コストは？」が出てきます。
* 審査員は“デモが動く”より“壊れ方を把握している”を見ます。

**改善案（最低限入れると強い）**

* 小さくてもいいので評価表を入れる：
  * ラベル付けした会議ログN件（手動でOK）
  * Precision / Recall（または誤検知率）
  * 代表的な誤検知例3つ＋対策
* “安全側を採用”は良い思想なので、 **誤検知が増える前提で運用設計** （通知の段階設計、サイレンス期間、承認UIなど）を書くと刺さる。※ただしまだそのような仕組みはないので今後設計なのか、今できる範囲で正しく記載する形になる。細かい疑問ポイントはあらかじめFAQを最後につけておくのがよさそう。

---

**C. データ取り扱い（プライバシー / 機密 / 監査）への言及が薄いと危険**

* Meet/Chatログを扱う＝審査員の頭の中は「機密・個人情報・監査・越権」です。
* ここが薄いと、どれだけ技術が良くても“エンタープライズ導入不可枠”に落ちやすい。

**改善案**

* 章を1つ追加して、以下を短く明記：
  * 保存するデータ / 保存しないデータ
  * マスキング方針（個人名、センシティブ語、など）
  * ロールベースアクセス（経営層に見せる粒度）
  * 監査ログ（いつ誰が何を見たか）
* これだけで“現場感”が跳ね上がります。　
  ※ここも具体は実装はできていないので、今後の設計コンセプト的には考えている整理にしたい。なのでFAQとかに最後乗せるのがよさそう。

---

**D. 「AIが人を呼び出す」思想は強いが、失敗時の制御（ガードレール）が弱く見える**

* 審査員が気にする問い：
  * 誤検知で経営層を呼び出し続けたら？（アラート疲れ）
  * 悪用（政治的に使われる）されたら？
  * LLMがそれっぽい説明を捏造したら？（説明可能性の罠）

**改善案**

* “Human-in-the-loop”を、ただの承認ではなく **制御設計**として書く：
  * 重要度で段階（通知→レビュー→承認依頼→強制議題化）
  * 説明文は根拠引用（発話ID/タイムスタンプ）付きに限定
  * モデルの確信度が低い時は「質問として投げる」など
    ※設計として考えられている範囲は本文で説明、構想のみはFAQで

---

**E. 文章の“熱量”が高いぶん、審査員には冗長に感じる箇所がある**

* 同じ核説明（0.6×0.4、PDCA、AIが人を呼ぶ）が後半でも繰り返されるので、
  審査員は「分かったから次（実験・設計・限界）を見せて」となりやすい。

**改善案**

* 審査員が読みたい順に並べ替えると刺さる：
  1. 何を解く？（課題定義）
  2. 何が新規？（差分）
  3. どう動く？（アーキテクチャ）
  4. どこが難所？（評価・運用・ガードレール）
  5. 限界は？（できないこと・今後）

## ②一般的なユーザー（学生エンジニア / 初級〜中級）視点の離脱要因

### 離脱しやすいところ（上から順に致命度高め）

**A. 冒頭〜中盤が“概念の圧”で、何を作ったかが掴みにくい**

* 「組織構造をリード」「構造的に壊れている」など強い主張が続く一方で、
  *結局なにが入力で、なにを出力して、どう使えるツールなの？* が腹落ちするまで時間がかかる。
* 初級者は「すごそうだけど難しそう」で離脱しがち。

**改善案**

* 冒頭に **TL;DR（3行）＋最短の利用イメージ（1枚）** を置く。
  * 例：
    * 入力：Meet議事録 + Chatログ
    * 出力：異常パターン検知（理由付き） + 誰に承認依頼するか + タスク実行案
    * 価値：会議で言いづらい撤退・修正を“議題として強制的に浮上”させる

---

**B. 造語・専門語の密度が高く、読みながら詰む**

* 「正当化フェーズ」「責任モデル」「組織グラフ」「アンサンブル」「エスカレーション」「閾値」…
  初〜中級者には“辞書がない小説”状態になりやすい。
* 「Zombie Project」も説明はあるけど、頻出するので早めに短く定義があると良い。

**改善案**

* 可能な範囲で辞書がいらない表現に修正する
* 不可能な部分のみ“用語ミニ辞書”を **最初の方**に置く
* 造語（B1_正当化フェーズ等）は  **最初の登場時だけ** 「一言定義」を固定で添える。

---

**C. 同じ説明が何度も出てきて、読んでる感覚がループする**
特に繰り返しが起きてる核はこの3つです：

* 「AIが人を呼び出す」
* 「ルール（0.6）×LLM（0.4）で統合」
* 「観測→評価→介入→実行→再観測（PDCA）」

初級者は「また同じ話だ」と感じた瞬間にスクロールが止まります。

**改善案（超効く）**

* これらは **“思想の要約”セクションに一回だけ集約**して、以降は参照リンクにする。
  例：「（仕組みの全体像は上の“3つの中核機能”参照）」で済ませる。

---

**D. 定量効果が強すぎて“ほんと？”となる（信頼性の壁）**

* 97%削減、35倍改善、年100-120億円…はインパクト大だけど、
  初級者は根拠が追えず「盛ってる？」に寄りやすい。
* “導入後（推定）”と書いてるのは良い。ただ、その推定の仕方が見えない。

**改善案**

* 初級者向けには、数字を減らして **1つだけ**に絞るのが読みやすい。
  例：「意思決定リードタイム短縮」だけ残し、他は折りたたみ/補足へ。
* “推定方法”を **式1行**でいいので書く（例：会議頻度×意思決定遅延の平均×機会損失単価、など）。

---

## 具体的に「削る/まとめる」と効く重複ポイント

この3つは、**“1回だけ丁寧に”＋他は短い参照**にすると読みやすさが一気に上がります。

1. **ハイブリッド評価（0.6×0.4）**
   * 「なぜ必要か」は一度で十分
   * 後半の同趣旨説明はカットして、実装詳細に寄せる
2. **4つの視点（Executive/Planning/Staff/Governance）**
   * 列挙は1回でOK
   * あとは「4視点（詳細は上記）」で略記
3. **PDCAループ**
   * 図は良い
   * 以降は“学習・改善”の具体（何を学習するのか：閾値？パターン？責任モデル？）に文章を使う

---

## “フレンドリー化”のための言い換えパターン（すぐ使える）

* 「構造的に壊れている」→ **「仕組み上、悪化が見えても止まらない構造になっている」**
* 「責任境界」→ **「誰が決めるべきかの線引き」**
* 「エスカレーション」→ **「上位者に判断を回す」**
* 「アンサンブル」→ **「複数の判定を合算して最終判断する」**
* 「正当化フェーズ」→ **「悪化してるのに“現状維持”が正当化される段階」**

---

## 最後に：2ペルソナ両対応の“構成テンプレ”（おすすめ）

* **冒頭** ：TL;DR（3行）＋デモGIF/動画
* **課題** ：1ストーリーで完結（Before/Afterは短く）
* **解決** ：3つの中核機能（ここに重複要素を集約）
* **技術** ：アーキテクチャ → 検知ロジック → 承認フロー → 実行
* **評価** ：小さくても実験（誤検知例＋対策）
* **運用/ガードレール** ：機密・監査・権限・アラート疲れ対策
* **限界と今後** ：やらないことも明記
* **リンク** ：GitHub / ドキュメント
