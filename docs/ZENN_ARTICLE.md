# 組織構造自体をリードする AIエージェント - Helm

[ここにデモ動画を配置]

## はじめに

> **「AIを賢くするのではない。  
> "人とAIでできた組織"を賢くする。」**

Helmは、**組織構造そのものをリードするAIエージェント**です。既存のAIエージェントがタスクや成果物を最適化するのに対し、Helmは**組織の意思決定プロセスが「構造的に壊れている」問題**を検知し、改善します。

本記事では、Helmの設計思想と実装について解説します。

## 問題提起：既存組織の意思決定は「構造的に壊れている」

[ここにスライド画像「問題提起：3つの壁」を配置]

組織の意思決定プロセスには、**構造・組織的な問題**が存在します。これは、個々のタスクや成果物の問題ではなく、組織の意思決定の仕組みそのものが「構造的に壊れている」という本質的な課題です。

### 課題：AI主導の意思決定を阻む「3つの壁」

#### 1. 責任境界の曖昧性

大企業では、研究開発で「この仮説は棄却すべきか」、新規事業で「この事業は撤退すべきか」という重要な判断の**責任者が不明確**になります。

例えば、四半期経営会議でKPI悪化が共有されたものの、戦略変更の議論が起きず、撤退選択肢が構造的に排除される。会議では「数字は厳しいが、戦略は間違っていないと思う」と正当化が続き、チャットでは「やめた方がいい」「撤退案を口に出せる空気じゃない」と本音が漏れているのに、それが会議には上がってこない。このような状況では、**誰が最終判断者なのかが不明確**になり、意思決定が遅延し続けます。

#### 2. バイアスによる修正困難化

**忖度・楽観・既得権益による歪み**が組織的なバイアスとなり、実験データや市場反応が乏しくなっても、構造的な軌道修正が起きません。

初期仮説への固執が組織的なバイアスとなり、「始めたからには」という心理が働き、代替案の検討が行われません。現状、代替案の検討率は**10%未満**ですが、これが意思決定の質を大きく低下させています。

#### 3. 人主導によるAI活用の限界

実験ログ・会議ログ・KPI変更履歴など、膨大なシグナルを人が手作業で監視する必要があります。AIは「呼び出されるだけ」の存在であり、組織の構造的問題を自ら検知することができません。

パーソル総合研究所「無駄な社内会議による企業損失額調査」（2018年9月）によると、部長級管理職の週平均会議時間は**8.6時間**で、経営層のレビュー負荷は**週15時間**にも及びます[^5]。しかし、このような人手による監視では、微細な予兆を見逃し、構造的問題が深刻化してから気づくことになります。

[^5]: 出典URL: https://rc.persol-group.co.jp/news/201809060935/（信頼性：高）

### 調査事例（大企業）：実データが示す深刻な現状

[ここにスライド画像「調査事例（大企業）」を配置]

従業員1,000名以上の企業では、以下の実データが報告されています：

**意思決定リードタイムの遅延**

株式会社IDEATECH「大企業・エンプラの意思決定プロセス実態調査」（2025年6月）によると、新規サービス導入の意思決定期間は、平均で**約4-5ヶ月（120-150日）**にのぼります[^1]。戦略的意思決定と新規事業の意思決定を平均すると、**平均意思決定リードタイムは70〜85日**となります。

**新規事業の高い失敗率**

新規事業の失敗率は、複数の調査で高い数値が報告されています：

- 株式会社スーパーソフトウエア「新規事業に関する実態調査」（2023年6月）：**6割以上（60%以上）が失敗**[^2]
- PwC Japan「新規事業開発の取り組みに関する実態調査2025年」（2025年11月）：投資回収まで至った企業は**約2割（20%）**のみ[^3]
- NTTデータ「なぜ81％の新規事業がグロースに失敗するのか？」（2024年9月）：**81%の事業が成長段階で失敗**[^4]

これらの調査結果を平均すると、**新規事業の失敗率は約70%**となります。

**年間機会損失**

意思決定遅延による機会損失は、大企業で**年間約20億円規模**にのぼる、という調査結果があります。

[^1]: 出典URL: https://prtimes.jp/main/html/rd/p/000000421.000045863.html（信頼性：高）
[^2]: 出典URL: https://prtimes.jp/main/html/rd/p/000000023.000004742.html（信頼性：高）
[^3]: 出典URL: https://www.pwc.com/jp/ja/knowledge/thoughtleadership/new-business-development-survey-2025.html（信頼性：高）
[^4]: 出典URL: https://www.nttdata.com/jp/ja/trends/event/archive/2024/097（信頼性：高）

### 既存ツールでは解決できない根本的な問題

既存のAIツールやプロジェクト管理ツール（Asana、Jira、CrewAI、AutoGenなど）は、**タスクや成果物を最適化**することに焦点を当てています。しかし、これらのツールでは解決できない根本的な問題があります：

- **「誰が判断するか」が不明確**：重要な判断（撤退判断、仮説棄却等）の責任者が曖昧
- **「いつ判断すべきか」が分からない**：構造的問題の兆候を検知する仕組みがない
- **「判断の質」が向上しない**：組織構造そのものの改善が行われない

これらは、タスク管理や成果物の最適化では解決できず、**組織構造そのものの観測・評価・再設計**が必要な問題です。

## どう解決するか：Helmの機能コンセプト

[ここにスライド画像「Helmの機能コンセプト」を配置]

Helmは、**組織そのものを評価・判断するシステム**を構築します。従来の「人がAIを呼び出す」から「AIが人を呼び出す」へ転換することで、組織の構造的問題を自動検知し、適切なタイミングで適切な人に判断を求める仕組みを実現します。

### Helmを構成する3つの中核機能

#### ① 多角的な評価・判断システム

Helmは、**ルールベース（0.6） × LLM（0.4）** のハイブリッド評価により、見落としのない統合判断を実現します。

ルールベース分析では、KPI下方修正回数、撤退議論の有無、判断集中率（最も多く発言した人の発言数 / 総発言数）などの定量的指標に基づいて、安全側のベースライン評価を行います。一方、マルチ視点LLM分析では、同じ会議ログとチャットログを、4つの異なる視点から評価します：

- **経営者視点（Executive、重み: 0.4）**：全社の業績・リスク・ステークホルダー責任の観点から評価
- **経営企画視点（Planning、重み: 0.3）**：KPI・事業ポートフォリオ・撤退/投資判断の観点から評価
- **現場視点（Staff、重み: 0.2）**：実行可能性と現場負荷の観点から評価
- **ガバナンス視点（Governance、重み: 0.1）**：報告遅延・隠れたリスク・コンプライアンスの観点から評価

これらの評価結果をアンサンブルスコアリング（統合評価）で統合することで、単一の評価軸では見落としがちな問題も、複数の視点から検知できるようになります。

#### ② AIが人を呼び出し、判断を依頼

構造的問題を検知すると、Helmは自動で**役員 / 部長 / スタッフ**を特定し、判断・承認を依頼します。

人がAIを監視するのではなく、**AIが組織を監視し、人に判断を求める**という逆転の発想を実現しています。責任モデル（組織内の各役割がどのような判断に責任を持つかを定義したモデル）に基づいて、適切なロールを決定し、「なぜこの人を呼び出すべきか」を説明可能な形で生成します。

#### ③ 学習・改善PDCAの自動化

Helmは、以下のループを自動で回します：

```
観測 → 評価 → 介入 → 実行 → 再観測
```

組織構造の「壊れ方」を学習し、時間とともに**組織自体が賢くなる**仕組みを実現します。例えば、Helmが検知した構造的問題に対して経営層が介入し、その結果を次のサイクルで再観測することで、組織の意思決定プロセスが継続的に改善されていきます。

### 思想の要約

> **「AIや人ではなく、組織を賢くする」**

Helmの対象は、タスクや成果物ではなく、**判断構造 / 責任境界 / 役割分担**です。組織構造そのものを**観測・評価・再設計**することで、組織の意思決定プロセスを根本的に改善します。

## Before / After 比較：具体的なシーンで見る変化

[ここにスライド画像「Before/After比較」を配置]

### BEFORE：人手による監視・判断

四半期経営会議でKPI悪化が共有されたが、戦略変更の議論が起きなかった場合を例に説明します。

**具体的なシーン：**

経営会議では、CFOが「モバイルARPUは前年同期比▲6.2%、5G設備投資は当初計画比＋18%」と報告しているのに、CEOは「厳しいが、我々の戦略自体は間違っていないと思う」と正当化し、会議の結論は「2025年度計画は維持。次回進捗報告は3か月後」となっています。

一方、会議後のチャットでは、「数字かなり厳しかったですね」「撤退案を口に出せる空気ではなかったですね」と本音が漏れているのに、それが会議には反映されません。

このような状況では、以下の問題が発生します：

- **見落とし**：膨大な会議・チャットログから予兆検知不可。構造的問題（正当化フェーズ、報告遅延、撤退判断の遅れ）が検知されない
- **遅延**：構造的問題に気づくのが遅い（1〜2週間、場合によっては数ヶ月）
- **バイアス**：忖度・「始めたからには」心理により、代替案の検討が行われない

**定量的な現状：**
- 意思決定リードタイム：**70-85日**
- Zombie Project検知率：**0%**（Zombie Projectとは、失敗しているにも関わらず継続されているプロジェクトのこと）
- 代替案検討率：**10%未満**
- 経営層レビュー負荷：**15h/週**

### AFTER：Helmによる自律支援

Helmが構造的問題を検知し、経営層を自動的に呼び出します。

**具体的なシーン：**

Helmが会議議事録とチャットログを分析し、マルチ視点評価システムにより構造的問題「B1_正当化フェーズ」（KPI悪化が続いているにも関わらず、戦略変更の議論が行われない状態）を検知します。アンサンブルスコアが69点で、閾値70点に近いため、エスカレーションが必要と判断されます。

Helmは自動的に経営層を呼び出し、「正当化フェーズの兆候が検出されました。構造的変更には経営層の承認が必要です。」というエスカレーション理由を生成します。経営層は、介入案（次回経営会議に撤退選択肢を含めた3案比較を強制議題化）を確認し、承認すると、AIが自律的にタスクを実行します。

3週間後の経営会議では、撤退案スライドが議題の1つとして自然に含まれ、CFOが「投資凍結オプション」の財務影響について具体的に言及するようになります。

**定量的な変化：**
- 意思決定リードタイム：**2日以内（97%削減、35倍改善）**
- Zombie Project検知率：**90%以上**
- 代替案検討率：**50%以上（5倍以上改善）**
- 経営層レビュー負荷：**3h/週（80%削減）**

**Helm導入による定量的効果（フェルミ推定）：**

| 指標 | 導入前（実データ） | 導入後（推定） | 改善率 |
|------|-------------------|---------------|--------|
| **意思決定リードタイム** | 70-85日 | 2日以内 | **97%削減、35倍改善** |
| **Zombie Project検知率** | 0% | 90%以上 | **90%以上** |
| **代替案検討率** | 10%未満 | 50%以上 | **5倍以上改善** |
| **経営層レビュー負荷** | 15h/週 | 3h/週 | **80%削減** |

**経済効果（フェルミ推定、信頼性：低）：**
- 意思決定速度改善による機会損失削減：年間**約19億円規模**（20億円→1億円以下）
- Zombie Project削減による無駄な投資削減：年間**約88億円規模**（123億円→35億円）
- 経営層の時間確保による機会創出：年間**約10億円規模**
- **合計：年間約100-120億円規模の経済効果**

## 実行プロセス：具体的な利用フロー

[ここにスライド画像「実行プロセス（5ステップ）」を配置]

Helmの実行プロセスを、実際の利用シーンを例に説明します。

### ステップ1：データ取り込み

Google Meet / Chat / 会議資料から議事録・ログを取得し、構造化します。

Google Meet APIから議事録を取得し、発言者抽出、KPI検出、撤退議論検出、リスク検出などのパース処理を実行します。Google Chat APIからチャットログを取得し、本音の兆候を検出します。すべての処理は、モックと実データで同じインターフェースを使っているため、切り替えが容易です。

### ステップ2：検知・評価

ルールベース＋マルチLLMで問題特定を行います。

ルールベース分析では、KPI下方修正回数、撤退議論の有無、判断集中率などの定量的指標に基づいて構造的問題を検知します。マルチ視点LLM分析では、4つのロール視点（経営者、経営企画、現場、ガバナンス）から同一データを評価し、アンサンブルスコアリングで統合します。

### ステップ3：アラート発行

責任モデル（組織内の各役割がどのような判断に責任を持つかを定義したモデル）に基づきAIが人を呼び出します。

構造的問題が検知されると、Helmは自動的に適切なロール（経営層等）を決定し、エスカレーション理由を生成します。例えば、「正当化フェーズの兆候が検出されました。構造的変更には経営層の承認が必要です。」という理由で、経営層に通知し、承認待ち状態になります。

### ステップ4：承認・指示

人が確認・修正し、AIに実行権限付与します。

経営層は、介入案（次回経営会議に撤退選択肢を含めた3案比較を強制議題化、撤退案の提案責任者を明示、KPIトリガーを数値で決める等）を確認し、「了承する」あるいは「一部修正して実行」を選択します。Helmは、判断の枠組みを用意しますが、最終的な意思決定は人間が行います。

### ステップ5：AI自律実行

タスク分解、資料作成、会議設定まで実行します。

経営層の承認後、HelmはADK（Agent Development Kit、Googleが提供するAIエージェント開発ツールキット）を使用したマルチエージェントシステムで自律的にタスクを実行します。具体的には、市場データ分析、社内データ統合、3案比較資料の自動生成、関係部署への事前通知、会議アジェンダの更新などを行います。進捗はWebSocket経由でリアルタイム配信され、ユーザーは待ち時間中も何が起きているかを把握できます。

## アーキテクチャ設計

[ここにシステムアーキテクチャ図を配置]

### データフロー構造

**Part1: Ingest → Detect**
データ取得から構造的問題検知まで

**Part2: Human-in-the-Loop → ADKマルチエージェント**
人の判断を起点にAIが自律実行

### システム全体図

```
┌─────────────────────────────────────────────────────────────┐
│                        フロントエンド                         │
│                    (Next.js + TypeScript)                    │
│                                                               │
│  ┌──────────────┐  ┌──────────────┐  ┌──────────────┐      │
│  │   Case1      │  │   Case2      │  │   Case3      │      │
│  │   デモページ   │  │   デモページ   │  │   デモページ   │      │
│  └──────┬───────┘  └──────────────┘  └──────────────┘      │
│         │                                                      │
│  ┌──────▼───────┐                                            │
│  │  API Client  │  (lib/api.ts)                              │
│  └──────┬───────┘                                            │
└─────────┼─────────────────────────────────────────────────────┘
          │ HTTP REST API / WebSocket
          │
┌─────────▼─────────────────────────────────────────────────────┐
│                      バックエンドAPI                            │
│                    (Python FastAPI)                            │
│                                                               │
│  ┌──────────────────────────────────────────────────────┐   │
│  │              APIエンドポイント層                        │   │
│  │  /api/meetings/ingest, /api/analyze, etc.            │   │
│  └──────────────────┬───────────────────────────────────┘   │
│                     │                                        │
│  ┌──────────────────▼───────────────────────────────────┐   │
│  │              サービス層                                │   │
│  │                                                       │   │
│  │  ┌──────────────┐  ┌──────────────┐                │   │
│  │  │ Google Meet  │  │ Google Chat  │                │   │
│  │  │   Service    │  │   Service    │                │   │
│  │  └──────────────┘  └──────────────┘                │   │
│  │                                                       │   │
│  │  ┌──────────────┐  ┌──────────────┐                │   │
│  │  │  Structure   │  │  LLM Service │                │   │
│  │  │   Analyzer   │  │  (Gemini)     │                │   │
│  │  └──────────────┘  └──────────────┘                │   │
│  │                                                       │   │
│  │  ┌──────────────┐  ┌──────────────┐                │   │
│  │  │  Multi-Role  │  │  Ensemble     │                │   │
│  │  │  LLM Analyzer│  │  Scoring      │                │   │
│  │  └──────────────┘  └──────────────┘                │   │
│  │                                                       │   │
│  │  ┌──────────────┐  ┌──────────────┐                │   │
│  │  │  Escalation  │  │  Output      │                │   │
│  │  │   Engine     │  │   Service    │                │   │
│  │  └──────────────┘  └──────────────┘                │   │
│  └───────────────────────────────────────────────────────┘   │
└───────────────────────────────────────────────────────────────┘
```

### データフロー

#### 1. データ取り込みフロー

```
Google Meet/Chat
      │
      ▼
[議事録/チャット取得]
      │
      ▼
[パース処理]
      │
      ├─→ [発言者抽出]
      ├─→ [KPI検出]
      ├─→ [撤退議論検出]
      └─→ [リスク検出]
      │
      ▼
[構造化データ]
```

#### 2. 構造的問題検知フロー（マルチ視点評価システム）

```
[構造化データ]
      │
      ├─────────────────────────────────────┐
      │                                     │
      ▼                                     ▼
[ルールベース分析]              [マルチ視点LLM分析]
[StructureAnalyzer]              [MultiRoleLLMAnalyzer]
      │                                     │
      │                                     ├─→ [Executive視点] (重み: 0.4)
      │                                     ├─→ [Corp Planning視点] (重み: 0.3)
      │                                     ├─→ [Staff視点] (重み: 0.2)
      │                                     └─→ [Governance視点] (重み: 0.1)
      │                                     │
      │                                     ▼
      │                              [各ロールの評価結果]
      │
      └─────────────────────────────────────┘
                      │
                      ▼
            [アンサンブルスコアリング]
            [EnsembleScoringService]
                      │
                      ├─→ スコア計算: 0.6 × ルールベース + 0.4 × LLM平均
                      ├─→ 重要度・緊急度: 安全側（最も強い）を採用
                      └─→ 説明文: ルールベース + 主要ロールのコメント
                      │
                      ▼
            [パターン検出結果]
                      │
                      ├─→ B1_正当化フェーズ
                      ├─→ ES1_報告遅延
                      └─→ A2_撤退判断の遅れ
                      │
                      ▼
            [アラート生成 & 結果保存]
```

#### 3. Executive呼び出しフロー

```
[アラート生成]
      │
      ▼
[エスカレーション判断]
      │
      ├─→ [責任モデル参照]
      ├─→ [組織グラフ参照]
      └─→ [ロール選択]
      │
      ▼
[Executive呼び出し]
      │
      ▼
[承認待ち]
      │
      ├─→ [承認] ──→ [AI実行開始]
      └─→ [却下] ──→ [終了]
```

#### 4. AI自律実行フロー

```
[承認完了]
      │
      ▼
[タスク生成 (LLM)]
      │
      ├─→ [タスク1: 市場データ分析]
      ├─→ [タスク2: 社内データ統合]
      ├─→ [タスク3: 資料生成]
      ├─→ [タスク4: 通知送信]
      └─→ [タスク5: 会議設定]
      │
      ▼
[Google Workspace API]
      │
      ├─→ [リサーチ]
      ├─→ [分析]
      ├─→ [資料作成]
      └─→ [通知]
      │
      ▼
[Google Drive API]
      │
      ▼
[結果保存 & ダウンロードURL生成]
```

## 技術スタック

| カテゴリ | 技術 | 選定理由 | 具体的活用方法 |
|---------|------|---------|---------------|
| **フロントエンド** | Next.js 16 | Reactベースのフレームワークで、SSRとSSGをサポート。デモページの高速表示を実現 | Case1/Case2/Case3のデモページを構築。API Client（lib/api.ts）でバックエンドと通信 |
| | TypeScript | 型安全性の確保により、開発時のエラーを早期発見 | APIレスポンスの型定義、コンポーネントの型安全性を確保 |
| | Tailwind CSS | ユーティリティファーストのCSSフレームワークで、迅速なUI開発を実現 | デモページのスタイリング、レスポンシブデザインの実装 |
| **バックエンド** | FastAPI | PythonベースのAPIフレームワークで、非同期処理とWebSocketをサポート | REST APIエンドポイント（/api/meetings/ingest, /api/analyze等）とWebSocketエンドポイント（/api/execution/{execution_id}/ws）を実装 |
| | Python 3.11+ | 主要なプログラミング言語。型ヒントとパフォーマンス改善を活用 | サービス層の実装、LLM統合、データ処理 |
| | Uvicorn | ASGIサーバーで、FastAPIの非同期処理をサポート | 本番環境でのAPIサーバーとして使用 |
| **AI/ML** | Gemini 2.0 Flash (Gen AI SDK) | Google Cloudの生成AIモデル。マルチ視点評価と構造的問題検知に最適 | マルチ視点LLM分析（4つのロール視点から評価）、構造的問題検知、タスク生成、説明文生成 |
| **データベース（将来実装）** | Firestore | NoSQLデータベース。組織グラフ（組織内の上下関係や報告関係を表す図）管理と構造的問題記録に適している | 組織グラフ管理、構造的問題記録、エスカレーション履歴の保存 |
| | BigQuery | データウェアハウス。時系列データ分析とメトリクス集計に最適 | 時系列データ分析、メトリクス集計、長期トレンド分析 |
| **Google Cloud統合** | Google Meet API | 議事録取得に使用 | 会議議事録の取得、発言者抽出、KPI検出 |
| | Google Chat API | チャットメッセージ取得に使用 | チャットログの取得、本音の兆候検出 |
| | Google Workspace API | 資料生成と通知送信に使用 | 資料ドラフト作成、関係者への通知送信 |
| | Google Drive API | ファイル保存と共有に使用 | 生成された資料の保存、ダウンロードURL生成 |
| **リアルタイム通信** | WebSocket | リアルタイム進捗更新に使用 | AI自律実行中の進捗をリアルタイムで配信 |

## Hybrid評価アーキテクチャ：なぜルール×LLMなのか

[ここにスライド画像「Hybrid評価アーキテクチャ」を配置]

Helmは、ルールベース分析とマルチ視点LLM分析を組み合わせたハイブリッド評価により、より信頼性の高い構造的問題検知を実現しています。なぜこの2つを組み合わせる必要があるのか、それぞれの限界と利点を説明します。

### ルールベースの限界と利点

ルールベース分析は、定量的指標（KPI下方修正回数、撤退議論の有無、判断集中率など）に基づいて構造的問題を検知します。これは安全側のベースラインとして機能し、**見逃しゼロの安全網**を提供します。

しかし、ルールベース分析には限界があります。数値は正常だが「空気が異常」を見逃す可能性があります。例えば、会議の数値は正常範囲内でも、チャットログから「撤退案を口に出せる空気じゃない」という本音が漏れている場合、ルールベースだけでは検知できません。

**INPUT（ルールベース）の検出条件：**
- KPI下方修正回数 > 2
- 撤退議論キーワード：なし
- 判断集中率（最も多く発言した人の発言数 / 総発言数） > 40%

### LLM単体の限界と利点

マルチ視点LLM分析は、4つのロール視点から同一データを評価することで、文脈理解により過剰反応を抑制します。

しかし、LLM単体にも限界があります。楽観バイアス・ハルシネーション（AIが事実ではない情報を生成すること）のリスクがあり、過剰なアラートを発する可能性があります。

**CONTEXT ANALYSIS（LLM）の4視点：**
- 経営者視点（0.4）：全社リスク
- 経営企画視点（0.3）：ポートフォリオ整合
- 現場視点（0.2）：現場負荷
- ガバナンス視点（0.1）：コンプラ・報告遅延

### FINAL DECISION：アンサンブルスコアリング

Helmは、ルールベース結果とLLM結果を統合することで、より保守的で信頼性の高い評価を実現します：

```
最終スコア = 0.6 × ルールベーススコア + 0.4 × LLM平均スコア
```

重要度・緊急度は、ルールベースと各ロールの結果のうち、**最も安全側（最も強い）の評価を強制採用**します。これにより、過小評価を避け、かつ過剰なアラートも避けるバランスを取っています。

このアプローチにより、ルールベースの客観性とLLMの柔軟性を両立し、単一の評価軸では見落としがちな問題も、複数の視点から検知できるようになります。

## 実装のハイライト

### 1. 構造的問題検知ロジック（マルチ視点評価システム）

Helmの核心となる構造的問題検知は、**ルールベース分析**と**マルチ視点LLM分析**を組み合わせた**アンサンブルスコアリング（統合評価）**により実現しています。

#### 処理フローの詳細

**ステップ1：データ取り込み**

Google Meet APIとGoogle Chat APIから議事録とチャットログを取得します。すべての処理は、モックと実データで同じインターフェースを使っているため、切り替えが容易です。

**ステップ2：パース処理**

発言者抽出、KPI検出、撤退議論検出、リスク検出などのパース処理を実行します。これにより、構造化されたデータが生成されます。

**ステップ3：ルールベース分析**

定量的指標（KPI下方修正回数、撤退議論の有無、判断集中率（最も多く発言した人の発言数 / 総発言数）等）に基づく安全側のベースライン評価を行います。これは、見逃しゼロの安全網として機能します。

**ステップ4：マルチ視点LLM分析**

4つのロール視点（Executive、Corp Planning、Staff、Governance）から同一データを評価します。各視点は、実際の組織における役割を模倣しており、それぞれ異なるプロンプト（指示文）を使用してLLMで評価します。

**ステップ5：アンサンブルスコアリング**

ルールベース結果とLLM結果を統合（0.6 × ルールベース + 0.4 × LLM平均）します。重要度・緊急度は、安全側（最も強い）を採用することで、過小評価を避けます。

**ステップ6：パターン検出**

B1_正当化フェーズ、ES1_報告遅延、A2_撤退判断の遅れ等のパターンを検出します。これらのパターンは、実際の組織運営でよく見られる問題を体系化したものです。

#### ルールベース分析の実装

ルールベース分析では、`StructureAnalyzer`クラスが定量的指標に基づく構造的問題検知を行います。KPI下方修正回数、撤退議論の有無、判断集中率（最も多く発言した人の発言数 / 総発言数）などを検出し、安全側のベースライン評価を提供します。

#### マルチ視点LLM分析の実装

`MultiRoleLLMAnalyzer`クラスが、4つのロール視点から同一データを評価します。各視点は、実際の組織における役割を模倣しており、それぞれ異なるプロンプト（指示文）を使用してLLMで評価します：

- **経営者視点（Executive、重み: 0.4）**: 全社の業績・リスク・ステークホルダー責任の観点から評価
- **経営企画視点（Corp Planning、重み: 0.3）**: KPI・事業ポートフォリオ・撤退/投資判断の観点から評価
- **現場視点（Staff、重み: 0.2）**: 実行可能性と現場負荷の観点から評価
- **ガバナンス視点（Governance、重み: 0.1）**: 報告遅延・隠れたリスク・コンプライアンスの観点から評価

4つのロール視点から同一データを評価することで、単一の評価軸では見落としがちな問題も、複数の視点から検知できるようになります。

#### アンサンブルスコアリング（統合評価）の実装

`EnsembleScoringService`クラスが、ルールベース結果とLLM結果を統合します。**アンサンブルスコアリング**とは、複数の評価方法の結果を組み合わせて、より信頼性の高い最終評価を出す手法です。

- **スコア計算**: 0.6 × ルールベーススコア + 0.4 × LLM平均スコア
- **重要度・緊急度**: 安全側（最も強い）を採用（過小評価を避けるため）
- **説明文**: ルールベースの説明と主要ロールのコメントを統合

この手法により、ルールベースの客観性とLLMの柔軟性を両立できます。

#### パターン検出の詳細

Helmは、組織の意思決定プロセスでよく見られる問題パターンを検出します。以下の3つの主要パターンを検出します：

**B1_正当化フェーズ**

KPI（重要業績評価指標）が下方修正されているにも関わらず、戦略変更や撤退の議論が行われない状態です。検出条件は、KPI下方修正が2回以上、撤退議論なし、判断集中率（最も多く発言した人の発言数 / 総発言数）40%以上です。

このパターンは、会議では正当化が続き、チャットでは本音が漏れているのに、それが会議には反映されない状況を検知します。

**ES1_報告遅延**

リスクが認識されているにも関わらず、上位への報告が遅延している状態です。検出条件は、リスク提起メッセージ存在、エスカレーション未完了、判断集中率50%未満です。

このパターンは、現場でリスクが認識されているのに、経営層に報告されていない状況を検知します。

**A2_撤退判断の遅れ**

事業の悪化が明らかなのに、撤退やピボット（方向転換）の議論が行われない状態です（主にLLM検出）。

このパターンは、事業の悪化が明らかなのに、撤退やピボットの議論が行われない状況を検知します。

これらのパターンは、実際の組織運営でよく見られる問題を体系化したものです。

### 2. AIが人を呼び出す仕組み

Helmは、構造的問題を検知すると、**自動的に適切なロール（経営層等）を呼び出す**という逆転の発想を実現しています。

人がAIを監視するのではなく、**AIが組織を監視し、人に判断を求める**設計です。これは、既存の「人がAIを呼び出す」でも「完全自動化」でもない、**新しいヒト×AIの共生関係**です。

#### エスカレーション判断エンジンの実装

`EscalationEngine`クラスが、**責任モデル**（組織内の各役割がどのような判断に責任を持つかを定義したモデル）に基づいて適切なロールを決定し、エスカレーション理由を生成します。

**エスカレーションの流れ：**

1. **構造的問題の検知**: アンサンブルスコアが閾値70点を超えると、エスカレーションが必要と判断されます
2. **責任モデルの参照**: 組織内の各役割がどのような判断に責任を持つかを定義したモデルを参照し、適切なロール（経営層等）を決定します
3. **エスカレーション理由の生成**: 「正当化フェーズの兆候が検出されました。構造的変更には経営層の承認が必要です。」などの理由を生成します
4. **通知と承認待ち**: 経営層に通知し、承認待ち状態になります

将来的には、**組織グラフ**（組織内の上下関係や報告関係を表す図）も参照して、より適切なエスカレーション先を決定できるようになります。

### 3. 学習・改善PDCAの自動化

Helmは、以下のループを自動で回します：

```
観測 → 評価 → 介入 → 実行 → 再観測
```

組織構造の「壊れ方」を学習し、時間とともに**組織自体が賢くなる**仕組みを実現します。例えば、Helmが検知した構造的問題に対して経営層が介入し、その結果を次のサイクルで再観測することで、組織の意思決定プロセスが継続的に改善されていきます。

#### AIエージェントの処理フロー

経営層の承認後、Helmは**ADK (Agent Development Kit、Googleが提供するAIエージェント開発ツールキット)**を使用したマルチエージェントシステムで自律的にタスクを実行します。

**マルチエージェントシステム**とは、複数のAIエージェント（専門的な役割を持つAIプログラム）が協調して動作するシステムです。Helmは、以下の3つのAIエージェントが協調して動作します：

1. **Research Agent（リサーチエージェント）**: 市場データや社内データのリサーチを担当
2. **Analysis Agent（分析エージェント）**: 構造的問題の検知とスコアリング、財務シミュレーションを担当
3. **Notification Agent（通知エージェント）**: 関係者への通知ドラフト作成、資料ドラフト作成を担当

各エージェントは独立して動作するため、並列処理が可能で、全体の実行時間を短縮できます。

**処理フローの詳細：**

1. **Executiveが介入案を承認**: 経営層が、介入案（次回経営会議に撤退選択肢を含めた3案比較を強制議題化）を確認し、承認します
2. **タスク生成**: LLMを使用してタスクを生成します（市場データ分析、社内データ統合、3案比較資料の自動生成、関係部署への事前通知、会議アジェンダの更新）
3. **タスク実行**: 各エージェントが並列または順次にタスクを実行します
4. **リアルタイム進捗配信**: WebSocket経由で進捗をリアルタイム配信し、ユーザーは待ち時間中も何が起きているかを把握できます
5. **結果保存**: 実行結果をGoogle Driveに保存し、ダウンロードURLを生成します

#### WebSocketによるリアルタイム進捗更新

各エージェントがタスクを完了するたびに、フロントエンドに進捗を送信します。これにより、ユーザーは待ち時間中も何が起きているかを把握でき、AI自律実行の透明性が向上します。

## デモンストレーション：実際の動作フロー

[ここにスライド画像「デモンストレーション」を配置]

デモでは、四半期経営会議でKPI悪化が共有されたが、戦略変更の議論が起きなかった場合を例に、以下の流れを紹介します：

### 1. Before（人だけの場合）

Helm導入前の状況では、構造的問題が検知されません。会議では正当化が続き、チャットでは本音が漏れているのに、それが会議には反映されません。

### 2. データ受領直後

議事録とチャットが取り込まれ、パース処理が実行されます。Google Meet APIから議事録を取得し、発言者抽出、KPI検出、撤退議論検出、リスク検出を行います。Google Chat APIからチャットログを取得し、本音の兆候を検出します。

### 3. Helm解析完了

マルチ視点評価システムにより構造的問題「B1_正当化フェーズ」（KPI悪化が続いているにも関わらず、戦略変更の議論が行われない状態）が検知されます。アンサンブルスコアは69点で、閾値70点に近いため、エスカレーションが必要と判断されます。

ルールベース分析と4つのロール視点（経営者、経営企画、現場、ガバナンス）からの評価を統合し、各視点の評価結果とアンサンブル結果が表示されます。例えば、経営企画視点では緊急度が**HIGH**と評価されており、これが最終的な緊急度決定に影響しています。

### 4. 経営層の判断

Helmが自動的に経営層を呼び出し、「正当化フェーズの兆候が検出されました。構造的変更には経営層の承認が必要です。」というエスカレーション理由を生成します。経営層は、介入案（次回経営会議に撤退選択肢を含めた3案比較を強制議題化）を確認し、承認します。

### 5. AI自律実行中

タスクが順次実行されます。WebSocket経由で進捗をリアルタイム配信され、ユーザーは待ち時間中も何が起きているかを把握できます。具体的には、市場データ分析、社内データ統合、3案比較資料の自動生成、関係部署への事前通知、会議アジェンダの更新などが実行されます。

### 6. 実行結果受領

生成された資料のダウンロードURLが表示されます。3案比較資料は、Google Driveに保存され、ダウンロード可能です。関係部署への通知は、8名に送信されました。

詳細は、冒頭のデモ動画をご覧ください。

## 既存AIエージェントとの差分

[ここにスライド画像「既存AIエージェントとの差分」を配置]

Helmは、既存のAIエージェント（CrewAI、AutoGen等）やプロジェクト管理ツール（Asana、Jira等）とは、根本的に異なるアプローチを取っています。

| 観点 | 既存AI | Helm |
|------|--------|------|
| 自律性 | 行動（タスクの自動実行） | 判断（構造的問題の検知とエスカレーション） |
| 責任 | 人間任せ（人が判断する） | 内部モデル化（責任モデルに基づく自動決定） |
| 組織 | 前提（組織構造は変わらない） | 最適化対象（組織構造そのものを観測・評価・再設計） |
| 人間 | 操作者（人がAIを呼び出す） | 呼び出される存在（AIが人を呼び出す） |
| 失敗分析 | 内容（タスクや成果物の問題） | 構造（組織構造の問題） |

既存ツールは「正しく動くAI」を作ってきましたが、Helmは「間違えない組織」を作ります。タスクや成果物を最適化するのではなく、判断構造・責任境界・役割分担を観測・評価・再設計することで、組織の意思決定プロセスを根本的に改善します。

## 将来展望

[ここにスライド画像「将来展望」を配置]

### 横展開ロードマップ

Helmは、新規事業・R&Dから始まり、様々な領域へ横展開していく計画です：

- **Phase1**：新規事業・R&D（現在）
- **Phase2**：危機管理・予算配分（6–12ヶ月）
- **Phase3**：組織変革・M&A（12–24ヶ月）
- **Phase4**：人事評価・昇進（24–36ヶ月）

### AI会社パッケージ（将来像）

将来的には、AIが以下を自動生成する「AI会社パッケージ」を実現することを目指しています：

1. 組織構造設計
2. メンバー選定
3. ロードマップ生成
4. 実作業提案

→ **数時間で体制構築、数日でPJ始動**

これにより、組織構造の観測・評価・再設計を実現し、組織が時間とともに賢くなっていく仕組みを提供します。

## まとめ

Helmは、**組織構造そのものをリードするAIエージェント**として、以下の特徴を持ちます：

1. **AIが人を呼び出す**: 構造的問題を検知すると、自動的に適切なロール（経営層等）を呼び出す
2. **多角的評価**: ルールベース（0.6） × LLM（0.4）のハイブリッド評価で、4つの視点（経営者、経営企画、現場、ガバナンス）から同時評価
3. **学習・改善PDCA**: 観測→評価→介入→実行→再観測のループを自動化し、組織自体が賢くなる
4. **構造最適化**: タスクや成果物ではなく、判断構造・責任境界・役割分担を観測・評価・再設計

**Helm導入による定量的効果（フェルミ推定）:**

| 指標 | 導入前（実データ） | 導入後（推定） | 改善率 |
|------|-------------------|---------------|--------|
| **意思決定リードタイム** | 70-85日 | 2日以内 | **97%削減、35倍改善** |
| **Zombie Project検知率** | 0% | 90%以上 | **90%以上**（Zombie Projectとは、失敗しているにも関わらず継続されているプロジェクトのこと） |
| **代替案検討率** | 10%未満 | 50%以上 | **5倍以上改善** |
| **経営層レビュー負荷** | 15h/週 | 3h/週 | **80%削減** |

**経済効果（フェルミ推定、信頼性：低）：**
- 意思決定速度改善による機会損失削減：年間**約19億円規模**（20億円→1億円以下）
- Zombie Project削減による無駄な投資削減：年間**約88億円規模**（123億円→35億円）
- 経営層の時間確保による機会創出：年間**約10億円規模**
- **合計：年間約100-120億円規模の経済効果**

Helmのビジョンは、**"Helm is where humans steer and AI rows."**です。

人は舵を取る。AIは船でありパドルでありレーダーである。

これは、既存の「人がAIを呼び出す」でも「完全自動化」でもない、**新しいヒト×AIの共生関係**です。

> **「AIを賢くするのではない。  
> "人とAIでできた組織"を賢くする。」**

## 参考資料

- [GitHubリポジトリ](https://github.com/your-org/helm) - ソースコード
- [APIドキュメント](http://localhost:8000/docs) - API仕様
- [アーキテクチャドキュメント](./ARCHITECTURE.md) - システム設計の詳細
