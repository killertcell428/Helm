## AI Agent Hackathon with Google Cloud

## 戦略定義書 v2（Helm版）

---

## 1. 本プロジェクトの戦略的ポジション

### プロジェクト名 / ブランド

- **サービス名**: `Helm（ヘルム）`
- **コンセプトタグライン**:
  - 「AIを賢くするのではない。**人とAIでできた組織**を賢くする。」
  - "Helm is where humans steer and AI rows."

### 一文定義

> **Helmは、新規事業など「正解のない不確実な領域」において、
> 人とAIから成る組織そのものを観測・評価・再設計する、
> 組織単位の自律改善型AIプラットフォームである。**

### 立ち位置（Google Cloudとの関係を含む上位レイヤー定義）

- **GoogleのAI群**:
  - 特化型AI / LLM（Gemini等） = 「優秀なスタッフ」
  - Agent系プロダクト / Orchestrator = 「タスク実行チーム」
- **Helm**:
  - これらを **「組織部品」として再編成し、責任・判断・ガバナンスを司る"上位レイヤーOS"**

---

## 2. 課題定義（審査基準：課題の新規性）

### 対象ドメイン

- B2B新規事業などの **新規事業開発プロジェクト**
- 共通点:
  - 正解が一つに定まらない
  - 要件・環境が頻繁に変化する
  - 判断と責任が属人化しやすい

### 表層課題（扱わない）

- 実験の自動化・高速化
- 文献調査の効率化
- KPIダッシュボードによる可視化

### 本質的な構造的課題（ここを突く）

プレゼン資料で定義されている **3つの構造的盲点** を統合し、Helmが扱う中心課題を次のように整理する。

1. **責任境界の不可視化**
   - 痛みを伴う判断（仮説棄却・事業撤退など）の「最終責任者」が曖昧
   - 意思決定リードタイムが不必要に長期化（例: 7–14日）
2. **構造固定化バイアス**
   - 初期仮説や既存の組織構造への執着により、構造的なピボットが起きない
   - 代替案（Plan B/C）の検討率が低い（例: <10 %）
3. **人主語の認知限界**
   - 実験ログ・会議ログ・KPI変更履歴など、膨大なシグナルを人が手作業で監視
   - 微細な「壊れ方の予兆」を見逃し、Zombie Project化・研究の惰性継続が発生

> **既存ツールは「タスク」や「成果物」を最適化してきたが、
> 「組織構造そのものの壊れ方」を観測し、介入する仕組みは存在しない。**

---

## 3. 解決アプローチ（審査基準：解決策の有効性）

### 解決策の核心

> **Helmは「仕事の中身」ではなく
> 研究チーム・事業チームの「判断構造・責任境界・役割分担」を
> AIによって観測・評価・再設計する。**

### 基本思想（人・AI・Helmの三位一体モデル）

- **人（Executive / PI / 事業責任者）**
  - 仮説立案・最終決断・価値判断・撤退判断の責任を持つ
  - 日常のタスク実行やログ解析は行わない
- **AI（Autonomous Agents）**
  - 実験・調査・高速検証など「試行を回す」役割
  - 新規事業の専門タスクを自律的に実行
- **Helm（STRUCTURAL GOVERNOR / Research Structure Manager 等）**
  - 成果・判断・介入ログを統合し、**「組織の壊れ方」** を検知
  - 構造的な欠陥（レビュー遅延・責任集中・正当化フェーズ移行 等）を特定
  - 役割再編・プロセス変更・エスカレーション等の **構造介入案** を提示

---

## 4. AI組織モデル（Helmが実現する組織像）

### 組織構成の原則（抽象モデル）

- **Human Executive**
  - 事業責任者 / 経営層
  - 役割: 仮説立案、最終決断、価値判断・トレードオフ、重大リスクの承認
- **AI Program Director / Structural Governor（Helm Core）**
  - プロジェクト全体の構造・責任モデルを保持
  - ログから「構造的壊れ方」を検知し、介入ポイントを決定
  - 「人を呼ぶべきか（エスカレーションすべきか）」を判断
- **AI Managers / Domain Agents**
  - KPI整合、構造分析、Business Decision Auditor 等
- **AI Staff**
  - 実験プロトコル生成、分析スクリプト作成、資料生成、レポート要約 等

> **人は「舵」を取り、AIは「漕ぐ」。
> Helmは、その船全体の構造と羅針盤を担う。**

---

## 5. PDCAの定義（本プロジェクトにおけるPDCAの再設計）

### 一般的なPDCA（扱わない）

- 実験精度の向上
- モデル性能やKPI達成度のみを対象とした改善

### HelmにおけるPDCA（改善対象 = 組織構造）

| フェーズ | 改善 / 観測対象                                          |
| -------- | -------------------------------------------------------- |
| Plan     | 組織構造・責任モデル・エスカレーションルール             |
| Do       | 新規事業チーム + AIエージェントによる施策実行            |
| Check    | Helmによる構造的壊れ方の検知 + Human Executiveのレビュー |
| Act      | 組織図・責任境界・プロセスの再設計                       |

### 評価指標（成果物ではなく「運営品質」にフォーカス）

- 意思決定リードタイム（例: 7–14日 → 48時間）
- 代替案（Plan B/C）の検討率（例: 20% → 65%）
- 責任所在の明確化率（例: 55% → 95%）
- Zombie Project化の防止率 / 撤退判断のリードタイム

> **「PDCAが成果物ではなく"組織構造"に対して回っている」こと自体を成果とする。**

---

## 6. Google Cloudとの関係性（競合回避戦略）

### 基本方針

> **Google CloudのAI・データ基盤は「組織の部品」。
> Helmは、それらを編成・評価・再配置し、
> 責任と判断のガバナンスを実装する"上位メタ構造"である。**

### 位置づけ（機能レイヤー別）

| Google技術 / 周辺技術              | Helmにおける役割                                         |
| ---------------------------------- | -------------------------------------------------------- |
| Vertex AI / Gemini                 | 各種Domain Agent / Staff（実行タスク担当）               |
| Agent Builder / ADK / LangGraph 等 | AI Manager / Orchestrator層の実装補助                    |
| BigQuery / Firestore               | 成果・判断・介入ログ、および組織構造・責任モデルの永続化 |
| Cloud Run                          | Helmコアエンジンの実行基盤                               |

> **「AIエージェントを置き換える」のではなく、
> それらを"責任と構造"の文脈に乗せ直すレイヤーとして振る舞うことで、Google既存プロダクトと正面衝突しない。**

---

## 7. 新規性の最終定義（審査員向けメッセージ）

### 参入障壁としての新規性（プレゼン内の3点を統合）

1. **責任を伴う判断モデルの内面化**
   - 「誰の責任か」を組織構造としてモデル化し、Low Risk / High Risk の境界に応じて
     - AI単独判断
     - 承認必須
     - 合議必須
       を切り替えるガバナンス構造
2. **組織構造そのものを評価対象にするメタ認知**
   - 成果物ではなく、レビュー遅延・責任集中・正当化フェーズ移行など
     **「壊れ方のパターン」** を観測・推論・最適化する
3. **AIが「自分の限界を知り、人を呼ぶ」振る舞い**
   - LLMの「何でも答えようとする」性質と対照的に、
     不確実性・リスク・責任範囲を構造化し、
     **手遅れ前に人間Executiveを呼び出す行動** をシステムとして実装

### 一言での新規性表現（ドラフト）

> **既存ツールは「正しく動くAI」を作ってきた。
> Helmは「間違えない組織」を作る。**

※ 最終的な一言コピーはコンペ全体のトーンに合わせて微調整の余地あり。

---

## 8. デモ・記事・プレゼンの統一メッセージ

### キャッチコピー候補

- 「AIを賢くするのではない。**人とAIでできた"組織"を賢くする。**」
- 「正解のない航海を導く、**組織単位の自律改善型AI — Helm —。**」

### 審査員に残したい最終メッセージ（プレゼン14枚目との整合）

> 「既存ツールは"正しく動くAI"を作ってきました。
> 私たちは**"間違えない組織"**を作ります。」

---

## 9. 戦略的ゴール

- AI Agent Hackathonにおいて
  - **「既存のエージェント文脈とは一線を画す"組織OS"として評価されること」**
- 技術デモではなく、
  - **「責任・判断・ガバナンスを扱う思想と構造」で評価されること**
- Google CloudのAI群を
  - **新規事業組織の"構造的ガバナンスOS"として再定義する一歩を示すこと**
